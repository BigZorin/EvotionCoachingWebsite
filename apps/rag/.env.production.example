# ============================================================
# Evotion RAG — Production Environment
# Copy to .env and fill in your values
# ============================================================

# Authentication (REQUIRED for production!)
AUTH_TOKEN=CHANGE_ME_to_a_strong_password
AUTH_ENABLED=true

# Groq (primary LLM - fast cloud inference)
GROQ_API_KEY=CHANGE_ME_to_your_groq_key
GROQ_MODEL=llama-3.3-70b-versatile
LLM_PROVIDER=groq

# Cerebras (secondary fallback — fast & free, automatic if Groq fails)
CEREBRAS_API_KEY=CHANGE_ME_or_leave_empty_to_skip
CEREBRAS_MODEL=llama3.1-8b
CEREBRAS_TIMEOUT=60

# OpenRouter (tertiary fallback — automatic if Groq & Cerebras fail)
OPENROUTER_API_KEY=CHANGE_ME_or_leave_empty_to_skip
OPENROUTER_MODEL=google/gemma-3-27b-it:free
OPENROUTER_TIMEOUT=60

# Ollama (embeddings only — handled by Docker Compose, don't change)
# OLLAMA_BASE_URL is set automatically via docker-compose.yml
EMBEDDING_MODEL=nomic-embed-text

# ChromaDB (persistent volume — don't change)
CHROMA_PERSIST_DIR=/app/data/chroma_db

# Chunking
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Upload
MAX_FILE_SIZE_MB=100
UPLOAD_DIR=/app/data/uploads

# Retrieval
TOP_K=15
MAX_TOP_K=50
SIMILARITY_THRESHOLD=0.65

# Chat
MAX_CONTEXT_CHUNKS=15
MAX_HISTORY_MESSAGES=20
SUMMARIZE_AFTER_MESSAGES=20
