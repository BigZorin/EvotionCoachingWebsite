# ========== Authentication ==========
# Set a secret token to protect your instance (required for public hosting)
AUTH_TOKEN=change-me-to-a-random-secret
# Set to false to disable auth (local development only)
AUTH_ENABLED=true

# ========== Groq (primary LLM - fast cloud inference) ==========
# Get your free API key at https://console.groq.com/keys
GROQ_API_KEY=gsk_your_key_here
GROQ_MODEL=llama-3.3-70b-versatile
LLM_PROVIDER=groq

# ========== Cerebras (secondary fallback — fast & free) ==========
# Get your free API key at https://cloud.cerebras.ai/
CEREBRAS_API_KEY=
CEREBRAS_MODEL=llama-3.3-70b
CEREBRAS_TIMEOUT=60

# ========== OpenRouter (tertiary cloud fallback) ==========
# Get your free API key at https://openrouter.ai/keys
OPENROUTER_API_KEY=
OPENROUTER_MODEL=meta-llama/llama-3.3-70b-instruct:free
OPENROUTER_TIMEOUT=60

# ========== Ollama (embeddings only — generation handled by cloud providers) ==========
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text

# ========== ChromaDB ==========
CHROMA_PERSIST_DIR=./data/chroma_db

# ========== Chunking ==========
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# ========== Upload ==========
MAX_FILE_SIZE_MB=100
UPLOAD_DIR=./data/uploads

# ========== Retrieval ==========
TOP_K=15
MAX_TOP_K=50
SIMILARITY_THRESHOLD=0.65

# ========== Chat ==========
MAX_CONTEXT_CHUNKS=15
MAX_HISTORY_MESSAGES=20
SUMMARIZE_AFTER_MESSAGES=20
