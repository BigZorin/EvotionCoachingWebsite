# ========== Authentication ==========
# Set a secret token to protect your instance (required for public hosting)
AUTH_TOKEN=change-me-to-a-random-secret
# Set to false to disable auth (local development only)
AUTH_ENABLED=true

# ========== Groq (primary LLM - fast cloud inference) ==========
# Get your free API key at https://console.groq.com/keys
GROQ_API_KEY=gsk_your_key_here
GROQ_MODEL=llama-3.3-70b-versatile
LLM_PROVIDER=groq

# ========== Ollama (embeddings + fallback, optional for cloud) ==========
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text
OLLAMA_GENERATION_MODEL=llama3.1:8b

# ========== ChromaDB ==========
CHROMA_PERSIST_DIR=./data/chroma_db

# ========== Chunking ==========
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# ========== Upload ==========
MAX_FILE_SIZE_MB=100
UPLOAD_DIR=./data/uploads

# ========== Retrieval ==========
TOP_K=15
MAX_TOP_K=50
SIMILARITY_THRESHOLD=0.65

# ========== Chat ==========
MAX_CONTEXT_CHUNKS=30
MAX_HISTORY_MESSAGES=20
SUMMARIZE_AFTER_MESSAGES=10
